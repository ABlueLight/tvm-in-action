{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Tensor Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TVM supports transparent code generation.\n",
    "- TVM supports black box function calls natively as well. \n",
    "- Specifically, TVM supports all tensor functions that are [DLPack](https://github.com/dmlc/dlpack) compatible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm \n",
    "import numpy as np \n",
    "from tvm.contrib import cblas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Extern Tensor Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1024\n",
    "l = 128\n",
    "m = 235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = tvm.var(name='bias', dtype=tvm.float32)\n",
    "A = tvm.placeholder(shape=(n, l), name='A')\n",
    "B = tvm.placeholder(shape=(l, m), name='B')\n",
    "# Compute several tensor via extern function.\n",
    "C = tvm.extern(shape=(n, m), inputs=[A, B], \n",
    "               fcompute=lambda ins, outs: tvm.call_packed(\"tvm.contrib.cblas.matmul\",\n",
    "                                                         ins[0], ins[1], outs[0], False, False),\n",
    "              name=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = tvm.compute(shape=C.shape, fcompute=lambda i, j: C[i, j] + bias, name=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tvm.create_schedule(D.op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = tvm.cpu(dev_id=0)\n",
    "f = tvm.build(sch=s, args=[A, B, D, bias], target=\"llvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tvm.nd.array(np.random.uniform(size=(n, l)).astype(A.dtype), ctx)\n",
    "b = tvm.nd.array(np.random.uniform(size=(l, m)).astype(B.dtype), ctx)\n",
    "d = tvm.nd.array(np.zeros((n, m), dtype=D.dtype), ctx)\n",
    "bb = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(a, b, d, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(\n",
    "    d.asnumpy(), np.dot(a.asnumpy(), b.asnumpy()) + 10, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extern Contrib Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TVM also provides extern contrib wrappers to useful extern calls, the following line is equivalent to the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib import cblas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = cblas.matmul(lhs=A, rhs=B)\n",
    "D = tvm.compute(shape=C.shape, fcompute=lambda i, j: C[i, j] + bias, name=\"D\")\n",
    "s = tvm.create_schedule(D.op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook Python Function as Extern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since we can call into any PackedFunc in TVM. We can use the extern function to callback into python.\n",
    "\n",
    "- The following example registers a python function into tvm runtime system and use it to complete one stage of the computation. \n",
    "- This makes TVM much more flexible. For example, we can insert front-end callbacks to inspect the intermediate results or mix customized code with TVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.register_func(\"tvm.contrib.my_tvm_addone\")\n",
    "def my_tvm_addone(x, y):\n",
    "    print(\"my_tvm_addone signatures: %s, %s\" % (type(x), type(y)))\n",
    "    tvm.nd.array(x.asnumpy() + 1).copyto(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tvm.placeholder((n,), name=\"A\")\n",
    "B = tvm.extern(A.shape, inputs=[A], \n",
    "               fcompute=lambda ins, outs: tvm.call_packed(\"tvm.contrib.my_tvm_addone\", \n",
    "                                              ins[0], outs[0]), \n",
    "               name=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tvm_addone signatures: <class 'tvm.ndarray.NDArray'>, <class 'tvm.ndarray.NDArray'>\n"
     ]
    }
   ],
   "source": [
    "s = tvm.create_schedule(B.op)\n",
    "f = tvm.build(s, [A, B], \"llvm\")\n",
    "a = tvm.nd.array(np.random.uniform(size=(n,)).astype(A.dtype), ctx)\n",
    "b = tvm.nd.array(np.random.uniform(size=(n,)).astype(B.dtype), ctx)\n",
    "f(a, b)\n",
    "np.testing.assert_allclose(b.asnumpy(), a.asnumpy() + 1, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
